# ğŸ“Š GCP E-commerce ELT & Machine Learning Pipeline

## ğŸ§  PrÃ©sentation du projet

Ce projet met en Å“uvre un **pipeline ELT complet et automatisÃ© sur Google Cloud Platform**, depuis lâ€™ingestion de donnÃ©es brutes jusquâ€™Ã  lâ€™entraÃ®nement dâ€™un **modÃ¨le de Machine Learning**, orchestrÃ© avec **Cloud Composer (Airflow)**.

ğŸ¯ **Objectifs**
- Construire une architecture data **cloud-native et scalable**
- Appliquer les bonnes pratiques **ELT (Extract â€“ Load â€“ Transform)**
- Produire des **tables analytiques fiables**
- CrÃ©er une **table ML-ready**
- EntraÃ®ner et Ã©valuer un **modÃ¨le de classification client**
- DÃ©montrer une dÃ©marche **professionnelle et reproductible**

---

## ğŸ—ï¸ Architecture globale

```
Kaggle CSV
â†“
Google Cloud Storage (RAW)
â†“
BigQuery RAW
â†“
BigQuery TRANSFORMED (STG, FACT)
â†“
BigQuery ML (features + model)
â†“
Airflow (Cloud Composer â€“ orchestration quotidienne)
```

---

## ğŸ“‚ Dataset

- **Source** : Kaggle â€“ *[Online Retail II](https://www.kaggle.com/datasets/mashlyn/online-retail-ii-uci)*
- **Type** : Transactions e-commerce
- **PÃ©riode** : 2009 â€“ 2011
- **DonnÃ©es** : factures, produits, clients, quantitÃ©s, montants

---

## â˜ï¸ Stack technique

- **Google Cloud Storage (GCS)** : stockage des donnÃ©es brutes
- **BigQuery** : moteur analytique & transformations ELT
- **Cloud Composer (Airflow)** : orchestration
- **BigQuery ML** : Machine Learning
- **Python** : DAG Airflow
- **SQL** : transformations & modÃ©lisation

---

## ğŸ“ Structure du projet
```
gcp-ecommerce-elt-ml/
â”‚
â”œâ”€â”€ airflow_dags/
â”‚ â””â”€â”€ ecom_elt_daily.py
â”‚
â”œâ”€â”€ queries/
â”‚ â”œâ”€â”€ staging_table.sql
â”‚ â”œâ”€â”€ modelisation_sql.sql
â”‚ â”œâ”€â”€ ML-ready-table.sql
â”‚ â””â”€â”€ bigquery_ml.sql
â”‚
â”œâ”€â”€ kaggle/
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## 1ï¸âƒ£ Ingestion des donnÃ©es (RAW)

### ğŸ“¥ TÃ©lÃ©chargement depuis Kaggle
```bash
kaggle datasets download -d mashlyn/online-retail-ii-uci
unzip online-retail-ii-uci.zip
```
ğŸ“¤ Upload vers Google Cloud Storage
```
gsutil cp online_retail_II.csv \
gs://gcs-elt-ecom-raw-euw1/raw/online_retail/ingestion_dt=2025-12-28/
```
## 2ï¸âƒ£ Chargement BigQuery (RAW)

Les donnÃ©es sont chargÃ©es depuis GCS vers BigQuery avec autodÃ©tection du schÃ©ma :

Dataset : ecom_raw

Table : raw_online_retail

Format : CSV

## 3ï¸âƒ£ Transformation ELT â€“ STAGING
ğŸ¯ **Objectifs**

Nettoyage minimal

Typage des colonnes

Suppression des valeurs incohÃ©rentes

Calcul des montants de ligne

```
CREATE OR REPLACE TABLE `online-retail-project1.ecom_transformed.stg_online_retail` AS
SELECT
  CAST(Invoice AS STRING) AS invoice_no,
  CAST(StockCode AS STRING) AS stock_code,
  CAST(Quantity AS INT64) AS quantity,
  CAST(Price AS NUMERIC) AS unit_price,
  SAFE_MULTIPLY(CAST(Quantity AS NUMERIC), CAST(Price AS NUMERIC)) AS line_amount,
  DATE(InvoiceDate) AS invoice_date,
  CAST(CAST(`Customer ID` AS INT64) AS STRING) AS customer_id,
  Country
FROM `online-retail-project1.ecom_raw.raw_online_retail`
WHERE Quantity > 0
  AND Price > 0
  AND `Customer ID` IS NOT NULL;
```

## 4ï¸âƒ£ Table de faits â€“ FACT_ORDERS
```
CREATE OR REPLACE TABLE `online-retail-project1.ecom_transformed.fact_orders` AS
SELECT
  invoice_no,
  invoice_date,
  customer_id,
  COUNT(*) AS total_items,
  SUM(line_amount) AS order_amount
FROM `online-retail-project1.ecom_transformed.stg_online_retail`
GROUP BY invoice_no, invoice_date, customer_id;

```
## 5ï¸âƒ£ Feature Engineering â€“ Table ML-ready

ğŸ¯ **Objectif**

CrÃ©er une table 1 ligne = 1 client pour le Machine Learning.
```
CREATE OR REPLACE TABLE `online-retail-project1.ecom_ml.features_customer_snapshot` AS
WITH ref AS (SELECT DATE '2011-12-09' AS snapshot_date)
SELECT
  customer_id,
  DATE_DIFF((SELECT snapshot_date FROM ref), MAX(invoice_date), DAY) AS recency_days,
  COUNT(DISTINCT invoice_no) AS total_orders,
  COUNT(DISTINCT IF(invoice_date >= DATE_SUB((SELECT snapshot_date FROM ref), INTERVAL 12 MONTH), invoice_no, NULL)) AS frequency_12m,
  SUM(IF(invoice_date >= DATE_SUB((SELECT snapshot_date FROM ref), INTERVAL 12 MONTH), order_amount, 0)) AS monetary_12m,
  IF(MAX(invoice_date) >= DATE_SUB((SELECT snapshot_date FROM ref), INTERVAL 90 DAY), 1, 0) AS is_active_90d
FROM `online-retail-project1.ecom_transformed.fact_orders`
GROUP BY customer_id;
```
## 6ï¸âƒ£ Orchestration avec Airflow (Cloud Composer)

ğŸ“¦ DÃ©ploiement du DAG
```
gsutil cp ecom_elt_daily.py \
gs://us-central1-online-retail-c-cbeefab9-bucket/dags/
```

â±ï¸ **Pipeline quotidien**

Le DAG exÃ©cute automatiquement :

* 1. Copie du fichier source vers ingestion_dt={{ ds }}

* 2. Chargement GCS â†’ BigQuery RAW

* 3. Recalcul STG

* 4. Recalcul FACT_ORDERS

* 5. Recalcul des features ML

âœ… **DAG** exÃ©cutÃ© quotidiennement avec succÃ¨s

## 7ï¸âƒ£ Machine Learning avec BigQuery ML

ğŸ¯ **ProblÃ©matique**

PrÃ©dire si un client sera actif dans les 90 prochains jours

ğŸ§ª ModÃ¨le final (sans data leakage)
```
CREATE OR REPLACE MODEL `online-retail-project1.ecom_ml.model_active_90d_lr_v2`
OPTIONS(
  model_type = 'LOGISTIC_REG',
  input_label_cols = ['is_active_90d'],
  data_split_method = 'AUTO_SPLIT',
  auto_class_weights = TRUE
) AS
SELECT
  is_active_90d,
  total_orders,
  frequency_12m,
  monetary_12m
FROM `online-retail-project1.ecom_ml.features_customer_snapshot`;
```

ğŸ“ˆ **RÃ©sultats du modÃ¨le**

| MÃ©trique  | Valeur   |
| --------- | -------- |
| ROC AUC   | **0.88** |
| Accuracy  | 0.78     |
| Precision | 0.82     |
| Recall    | 0.72     |
| F1-score  | 0.77     |

âœ” ModÃ¨le rÃ©aliste

âœ” Pas de fuite dâ€™information

âœ” Exploitable mÃ©tier

---

ğŸ§  **Points forts du projet**

- Architecture ELT cloud-native

- Orchestration Airflow en production

- SQL analytique structurÃ©

- DÃ©tection et correction dâ€™un data leakage

- Pipeline automatisÃ© et reproductible

- ML intÃ©grÃ© directement dans BigQuery

ğŸ”œ **AmÃ©liorations possibles**

- Boosted Trees (BigQuery ML)

- Ajout de nouvelles features comportementales

- Alerting Airflow

- Dashboard Power BI / Looker

## ğŸ‘¤ Auteur

Mamadou DIEDHIOU

Data Analyst / ChargÃ© dâ€™Ã©tudes statistiques
